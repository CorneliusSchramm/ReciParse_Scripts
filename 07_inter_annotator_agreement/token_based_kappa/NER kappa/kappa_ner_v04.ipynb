{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit ('nlp-env': conda)",
   "metadata": {
    "interpreter": {
     "hash": "60fbc5e2f5b4885e593b07e8327173f952414593b97953f7f5df8cd3c66845df"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonlines\n",
    "import spacy\n",
    "import spacy.language\n",
    "from spacy.tokens import Doc\n",
    "from spacy.scorer import Scorer\n",
    "from spacy.vocab import Vocab\n",
    "import statsmodels\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to jsonl overlap files\n",
    "path_coco = r\"/Users/jhoff/Universität St.Gallen/STUD-Capstoneproject Tell 6 - Dokumente/General/02-Coding/01-Data/20_overlap/overlap_total/overlap_coco.jsonl\"\n",
    "path_graf = r\"/Users/jhoff/Universität St.Gallen/STUD-Capstoneproject Tell 6 - Dokumente/General/02-Coding/01-Data/20_overlap/overlap_total/overlap_leo.jsonl\"\n",
    "path_hoff = r\"/Users/jhoff/Universität St.Gallen/STUD-Capstoneproject Tell 6 - Dokumente/General/02-Coding/01-Data/20_overlap/overlap_total/overlap_jona.jsonl\"\n",
    "path_jthn = r\"/Users/jhoff/Universität St.Gallen/STUD-Capstoneproject Tell 6 - Dokumente/General/02-Coding/01-Data/20_overlap/overlap_total/overlap_jonathan.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jsonl_to_list(path):\n",
    "    \"\"\"takes path to jsonl file and returns list of dicts\"\"\"\n",
    "    \n",
    "    with jsonlines.open(path) as reader:\n",
    "        list_of_dicts = list(reader)\n",
    "\n",
    "    return list_of_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_per_token(recipe):\n",
    "    \"\"\"takes annotated recipes as input and returns a dict that maps label to every token\"\"\"\n",
    "\n",
    "    amount_tokens = len(recipe[\"tokens\"])\n",
    "\n",
    "    all_token_dict = { tuple(range(token[\"start\"], token[\"end\"]+1)) : \"None\" for token in recipe[\"tokens\"]}    # each token as list and value \"None\"\n",
    "\n",
    "    for span in recipe[\"spans\"]:\n",
    "\n",
    "        all_chars = list(range(span[\"start\"], span[\"end\"]+1))\n",
    "\n",
    "        label = span[\"label\"]\n",
    "\n",
    "        for char in all_chars:              #compare all characters with all token characters\n",
    "            for tok in all_token_dict.keys():\n",
    "                if char in tok: \n",
    "                    all_token_dict[tok] = label\n",
    "    \n",
    "    #print(f\"Amount tokens: {amount_tokens} vs. Length dict: {len(all_token_dict.keys())}\")\n",
    "\n",
    "    return all_token_dict #{token: label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_table_per_recipe(recipe):\n",
    "    \"\"\"takes example annotated recipe and creates empty dict with token_start_char as indices and ent classes as column labels\"\"\"\n",
    "\n",
    "    columns = [\"Tokens\", \"Z\", \"TOOL\", \"V\", \"ATTR\", \"PRÄP\", \"ZEITP\", \"DAUER\", \"TEMP\", \"None\"]\n",
    "\n",
    "    token_table = pd.DataFrame(columns=columns)\n",
    "\n",
    "    toks = [tuple(range(token[\"start\"], token[\"end\"]+1)) for token in recipe[\"tokens\"]]\n",
    "\n",
    "    token_table[\"Tokens\"] = toks\n",
    "\n",
    "    token_table.fillna(0, inplace=True)\n",
    "\n",
    "    return token_table  #pd style table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_kappa(table):\n",
    "    \"\"\"takes table with tokens and labels as input and returns kappa\"\"\"\n",
    "\n",
    "    from statsmodels.stats.inter_rater import fleiss_kappa \n",
    "\n",
    "    \n",
    "    kappa = statsmodels.stats.inter_rater.fleiss_kappa(table, method=\"fleiss\")\n",
    "\n",
    "\n",
    "    return kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of individual overlap dicts\n",
    "ov_recipes_coco = jsonl_to_list(path_coco)\n",
    "ov_recipes_graf = jsonl_to_list(path_graf)\n",
    "ov_recipes_hoff = jsonl_to_list(path_hoff)\n",
    "ov_recipes_jthn = jsonl_to_list(path_jthn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dict for each annotator: key=text of recipe, value = ent_set\n",
    "ov_dict_coco = {example[\"text\"] : label_per_token(example) for example in ov_recipes_coco}\n",
    "ov_dict_graf = {example[\"text\"] : label_per_token(example) for example in ov_recipes_graf}\n",
    "ov_dict_hoff = {example[\"text\"] : label_per_token(example) for example in ov_recipes_hoff}\n",
    "ov_dict_jthn = {example[\"text\"] : label_per_token(example) for example in ov_recipes_jthn}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ov_all_dicts = [ov_dict_coco, ov_dict_jthn, ov_dict_graf, ov_dict_hoff]\n",
    "annot_names = [\"Coco\", \"Giov\", \"Graf\", \"Hoff\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create list with empty df per recipe \n",
    "recipe_table_dict = {example[\"text\"] : token_table_per_recipe(example) for example in ov_recipes_coco}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Recipe was skipped.\n",
      "Recipe was skipped.\n",
      "Recipe was skipped.\n",
      "Recipe was skipped.\n",
      "Recipe was skipped.\n",
      "Recipe was skipped.\n",
      "Recipe was skipped.\n",
      "Recipe was skipped.\n"
     ]
    }
   ],
   "source": [
    "for person in ov_all_dicts:                 #loop through all annotators\n",
    "    for example_recipe in person.keys():    #loop through all recipes of each annotator example_recipe = text\n",
    "        \n",
    "        try: \n",
    "            dataframe = recipe_table_dict[example_recipe]\n",
    "\n",
    "            for key in person[example_recipe].keys():  #loop through label_per_tok\n",
    "                        \n",
    "                    i = dataframe.index[dataframe[\"Tokens\"] == key]\n",
    "                    col_i = dataframe.columns.get_loc(person[example_recipe][key])\n",
    "                    dataframe.iloc[i, col_i] += 1\n",
    "\n",
    "        except: \n",
    "            pass\n",
    "            #print(\"Recipe was skipped.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "skip\nskip\nskip\n24\n"
     ]
    }
   ],
   "source": [
    "recipe_table_dict\n",
    "list = []\n",
    "for recipe in recipe_table_dict.values():\n",
    "    if recipe[[\"Z\", \"TOOL\", \"V\", \"ATTR\", \"PRÄP\", \"ZEITP\", \"DAUER\", \"TEMP\", \"None\"]].iloc[0].sum() == 4:\n",
    "        list.append(recipe)\n",
    "    else:\n",
    "        print(\"skip\")\n",
    "print(len(list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concat\n",
    "df_con = pd.concat(list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop column\n",
    "df_con_dropped = df_con.drop([\"Tokens\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      Z  TOOL  V  ATTR  PRÄP  ZEITP  DAUER  TEMP  None\n",
       "0     0     0  0     0     0      0      0     0     4\n",
       "1     0     0  0     0     0      0      0     0     4\n",
       "2     0     0  0     0     0      0      0     0     4\n",
       "3     0     0  0     0     0      0      0     0     4\n",
       "4     0     0  0     0     0      0      0     0     4\n",
       "...  ..   ... ..   ...   ...    ...    ...   ...   ...\n",
       "2852  0     0  4     0     0      0      0     0     0\n",
       "2853  0     0  0     0     0      0      0     0     4\n",
       "2854  0     0  0     1     0      3      0     0     0\n",
       "2855  0     0  4     0     0      0      0     0     0\n",
       "2856  0     0  4     0     0      0      0     0     0\n",
       "\n",
       "[2857 rows x 9 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Z</th>\n      <th>TOOL</th>\n      <th>V</th>\n      <th>ATTR</th>\n      <th>PRÄP</th>\n      <th>ZEITP</th>\n      <th>DAUER</th>\n      <th>TEMP</th>\n      <th>None</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2852</th>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2853</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2854</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2855</th>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2856</th>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>2857 rows × 9 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 161
    }
   ],
   "source": [
    "df_con_dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Overall: 0.949\n"
     ]
    }
   ],
   "source": [
    "#token-level kappa\n",
    "kappa = fleiss_kappa(df_con_dropped, method=\"fleiss\")\n",
    "print(f\"Overall: {round(kappa, 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Z: 0.963\n",
      "TOOL: 0.939\n",
      "V: 0.992\n",
      "ATTR: 0.886\n",
      "PRÄP: 0.974\n",
      "ZEITP: 0.865\n",
      "DAUER: 0.96\n",
      "TEMP: 0.855\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "entities = [\"Z\", \"TOOL\", \"V\", \"ATTR\", \"PRÄP\", \"ZEITP\", \"DAUER\", \"TEMP\"]\n",
    "for entity in entities: \n",
    "    df2 = df_con_dropped.iloc[:, np.r_[df_con_dropped.columns.get_loc(entity), df_con_dropped.columns.get_loc(\"None\")]]\n",
    "    #print(df2)\n",
    "    for i in range(len(df2)):\n",
    "        if df2.iloc[i, :].sum() != 4:\n",
    "            missing = 4 - (df2.iloc[i, 0] + df2.iloc[i, 1])\n",
    "            df2.iloc[i, 1] += missing\n",
    "    #print(df2)\n",
    "    kap = fleiss_kappa(df2)\n",
    "    print(f\"{entity}: {round(kap, 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}