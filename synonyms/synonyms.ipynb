{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.3 64-bit ('nlp-env': conda)",
   "display_name": "Python 3.8.3 64-bit ('nlp-env': conda)",
   "metadata": {
    "interpreter": {
     "hash": "e94a195423c03e6ca221f6d7bf4668d5d41ff3942174bd0f98efe498da7be866"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\\nInput: Textual Data\\nOutput: Same Data cleaned for synonyms\\nGrund: In German kitchen jargon there exist a lot of alternatives for words regarding food and tools depending on the region the recipe authour is from. Like to normalize that for the step by step guide.\\n'"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "\"\"\"\n",
    "Input: Textual Data\n",
    "Output: Same Data cleaned for synonyms\n",
    "Grund: In German kitchen jargon there exist a lot of alternatives for words regarding food and tools depending on the region the recipe authour is from. Like to normalize that for the step by step guide.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# References\n",
    "# https://www.youtube.com/watch?v=mCJ3wzjiNvA\n",
    "# https://spacy.io/usage/vectors-similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarity gets better with larger models. check\n",
    "nlp = spacy.load('de_core_news_lg', disable=['parser', 'tagger', 'ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[ 0.24403 -3.4729  -2.9564   1.0566  -1.0356 ] ... – Dimensions:  300\n[ 0.85765 -3.1901  -2.6978   1.3871  -2.6844 ] ... – Dimensions:  300\n\nSimilarity:  0.8424929889814099\n"
     ]
    }
   ],
   "source": [
    "# Pretrained word vectors by spacy\n",
    "doc1 = nlp(\"würzen\")\n",
    "doc2 = nlp(\"abschmecken\")\n",
    "print(doc1.vector[:5],\"...\", \"– Dimensions: \", len(doc1.vector))\n",
    "print(doc2.vector[:5],\"...\", \"– Dimensions: \", len(doc1.vector))\n",
    "# Resulting Similarity\n",
    "print(\"\")\n",
    "print(\"Similarity: \",doc1.similarity(doc2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Hund True 57.446507 False\nKatze True 43.214478 False\nMaus True 44.95886 False\nElefant True 24.972677 False\nRatte True 32.157112 False\nTiger True 34.42378 False\nLöwe True 39.592545 False\n"
     ]
    }
   ],
   "source": [
    "doc3 = nlp(\"Hund Katze Maus Elefant Ratte Tiger Löwe\")\n",
    "sim_list = [(token1.text,token2.text,token1.similarity(token2)) for token2 in doc3 for token1 in doc3]\n",
    "sim_list[:3]\n",
    "for token in doc3:\n",
    "    print(token.text, token.has_vector, token.vector_norm, token.is_oov)     # oov: hat ein token einen vector? has_vector: Ist ein Vector mit dem token assoziiert? --> Hä"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Token 1 Token 2  Similarity\n",
       "0     Hund    Hund    1.000000\n",
       "1    Katze    Hund    0.676083\n",
       "2     Maus    Hund    0.381736\n",
       "3  Elefant    Hund    0.441017\n",
       "4    Ratte    Hund    0.516697"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Token 1</th>\n      <th>Token 2</th>\n      <th>Similarity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Hund</td>\n      <td>Hund</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Katze</td>\n      <td>Hund</td>\n      <td>0.676083</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Maus</td>\n      <td>Hund</td>\n      <td>0.381736</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Elefant</td>\n      <td>Hund</td>\n      <td>0.441017</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Ratte</td>\n      <td>Hund</td>\n      <td>0.516697</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "df = pd.DataFrame(sim_list)\n",
    "df.columns = [\"Token 1\", \"Token 2\", \"Similarity\"]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check similarities without adjusted training data\n",
    "# Load the vocab of the recipes\n",
    "# Ich weiss nicht ob der Kontext wichtig ist, falls ja ist das hier Bullshit\n",
    "tokens_df = pd.read_pickle(\"/Users/Leonidas/Universität St.Gallen/STUD-Capstoneproject Tell 6 - General/Coding/cleaned_tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "677\n412\n"
     ]
    }
   ],
   "source": [
    "print(len(tokens_df))\n",
    "# Remove duplicates\n",
    "tokens = list(set(tokens_df[0]))\n",
    "print(len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [ nlp(token) for token in tokens ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = [ (token, token.vector_norm) for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Our word:  Grad\nHighest Similarity:  ('Minuten', 0.4862608255737344)\nOur word:  Spargelstücke\nHighest Similarity:  ('Spargelspitzen', 0.7774956571528802)\nOur word:  min\nHighest Similarity:  ('Min', 0.8343673976416094)\nOur word:  bringen\nHighest Similarity:  ('ziehen', 0.6820054354857157)\nOur word:  vermengen\nHighest Similarity:  ('vermischen', 0.8338406724168218)\nOur word:  Sauce\nHighest Similarity:  ('Marinade', 0.7751357985489428)\nOur word:  Vanillemark\nHighest Similarity:  ('Vanillezucker', 0.8122022587341052)\nOur word:  gegriffen\nHighest Similarity:  ('reichen', 0.520744661664803)\nOur word:  abtropfen\nHighest Similarity:  ('abgießen', 0.772762118240911)\nOur word:  Sauerkraut\nHighest Similarity:  ('Kartoffeln', 0.7530034767192818)\nOur word:  weglassen\nHighest Similarity:  ('abziehen', 0.6650948011533647)\nOur word:  köcheln\nHighest Similarity:  ('Köcheln', 0.7658935677630981)\nOur word:  Suppe\nHighest Similarity:  ('Brühe', 0.7615803094716043)\nOur word:  Sauerkirschen\nHighest Similarity:  ('Kirschen', 0.9384694970306531)\n*\nOur word:  Petersilie\nHighest Similarity:  ('Rosmarin', 0.7202511961538722)\nOur word:  Speck\nHighest Similarity:  ('Käse', 0.7046687281345356)\nOur word:  warm\nHighest Similarity:  ('heiß', 0.6920985012159969)\nOur word:  beiseite\nHighest Similarity:  ('Seite', 0.4064021000077441)\nOur word:  Obst\nHighest Similarity:  ('Gemüse', 0.8591823990408439)\n*\nOur word:  Marinade\nHighest Similarity:  ('Sauce', 0.7751357985489428)\n"
     ]
    }
   ],
   "source": [
    "# Print the most similar for each token\n",
    "trim = 20\n",
    "for query in tokens[:trim]:\n",
    "    print(\"Our word: \", query)\n",
    "    closest = (None, 0)\n",
    "    for token in tokens:\n",
    "        if query.similarity(token) > closest[1] and query.similarity(token) != 1:\n",
    "            closest = (token.text, query.similarity(token))\n",
    "    print(\"Highest Similarity: \", closest)\n",
    "    if closest[1] > 0.85:\n",
    "            print(\"*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[ 1.    0.15  0.4  ... -0.08  0.1   0.04]\n",
      " [ 0.15  1.    0.07 ...  0.13  0.49  0.06]\n",
      " [ 0.4   0.07  1.   ... -0.17  0.07  0.1 ]\n",
      " ...\n",
      " [-0.08  0.13 -0.17 ...  1.   -0.08  0.05]\n",
      " [ 0.1   0.49  0.07 ... -0.08  1.    0.15]\n",
      " [ 0.04  0.06  0.1  ...  0.05  0.15  1.  ]]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "               Grad  Spargelstücke   min  bringen  vermengen  Sauce  \\\n",
       "Grad           1.00           0.15  0.40     0.03       0.20   0.10   \n",
       "Spargelstücke  0.15           1.00  0.07     0.17       0.48   0.58   \n",
       "min            0.40           0.07  1.00    -0.09       0.04   0.05   \n",
       "bringen        0.03           0.17 -0.09     1.00       0.48   0.03   \n",
       "vermengen      0.20           0.48  0.04     0.48       1.00   0.34   \n",
       "...             ...            ...   ...      ...        ...    ...   \n",
       "Baguette       0.07           0.51  0.07     0.02       0.16   0.54   \n",
       "Schiene        0.15           0.26  0.10     0.11       0.23   0.15   \n",
       "mehreren      -0.08           0.13 -0.17     0.24       0.40  -0.00   \n",
       "Sauerrahm      0.10           0.49  0.07    -0.03       0.24   0.62   \n",
       "hart           0.04           0.06  0.10     0.08       0.10   0.14   \n",
       "\n",
       "               Vanillemark  gegriffen  abtropfen  Sauerkraut  ...  Zucker  \\\n",
       "Grad                  0.06       0.02       0.20        0.12  ...    0.17   \n",
       "Spargelstücke         0.48       0.18       0.49        0.57  ...    0.47   \n",
       "min                   0.09      -0.13       0.15        0.06  ...    0.08   \n",
       "bringen               0.03       0.43       0.20        0.13  ...    0.09   \n",
       "vermengen             0.38       0.44       0.53        0.35  ...    0.45   \n",
       "...                    ...        ...        ...         ...  ...     ...   \n",
       "Baguette              0.42       0.07       0.35        0.54  ...    0.33   \n",
       "Schiene               0.06       0.20       0.20        0.15  ...    0.16   \n",
       "mehreren              0.02       0.21       0.09        0.09  ...    0.08   \n",
       "Sauerrahm             0.57       0.01       0.45        0.67  ...    0.49   \n",
       "hart                  0.10       0.10       0.20        0.16  ...    0.14   \n",
       "\n",
       "               feine  steif    Ca  allerbesten  Baguette  Schiene  mehreren  \\\n",
       "Grad            0.01   0.13  0.07         0.00      0.07     0.15     -0.08   \n",
       "Spargelstücke   0.37   0.13  0.04         0.28      0.51     0.26      0.13   \n",
       "min            -0.03   0.14  0.23        -0.15      0.07     0.10     -0.17   \n",
       "bringen         0.21  -0.01 -0.02         0.34      0.02     0.11      0.24   \n",
       "vermengen       0.25   0.14  0.02         0.35      0.16     0.23      0.40   \n",
       "...              ...    ...   ...          ...       ...      ...       ...   \n",
       "Baguette        0.32   0.12  0.04         0.18      1.00     0.17     -0.02   \n",
       "Schiene         0.12   0.23 -0.01         0.01      0.17     1.00      0.09   \n",
       "mehreren        0.13   0.01  0.04         0.41     -0.02     0.09      1.00   \n",
       "Sauerrahm       0.19   0.26  0.01         0.08      0.54     0.17     -0.08   \n",
       "hart            0.22   0.53  0.02         0.18      0.10     0.17      0.05   \n",
       "\n",
       "               Sauerrahm  hart  \n",
       "Grad                0.10  0.04  \n",
       "Spargelstücke       0.49  0.06  \n",
       "min                 0.07  0.10  \n",
       "bringen            -0.03  0.08  \n",
       "vermengen           0.24  0.10  \n",
       "...                  ...   ...  \n",
       "Baguette            0.54  0.10  \n",
       "Schiene             0.17  0.17  \n",
       "mehreren           -0.08  0.05  \n",
       "Sauerrahm           1.00  0.15  \n",
       "hart                0.15  1.00  \n",
       "\n",
       "[200 rows x 200 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Grad</th>\n      <th>Spargelstücke</th>\n      <th>min</th>\n      <th>bringen</th>\n      <th>vermengen</th>\n      <th>Sauce</th>\n      <th>Vanillemark</th>\n      <th>gegriffen</th>\n      <th>abtropfen</th>\n      <th>Sauerkraut</th>\n      <th>...</th>\n      <th>Zucker</th>\n      <th>feine</th>\n      <th>steif</th>\n      <th>Ca</th>\n      <th>allerbesten</th>\n      <th>Baguette</th>\n      <th>Schiene</th>\n      <th>mehreren</th>\n      <th>Sauerrahm</th>\n      <th>hart</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Grad</th>\n      <td>1.00</td>\n      <td>0.15</td>\n      <td>0.40</td>\n      <td>0.03</td>\n      <td>0.20</td>\n      <td>0.10</td>\n      <td>0.06</td>\n      <td>0.02</td>\n      <td>0.20</td>\n      <td>0.12</td>\n      <td>...</td>\n      <td>0.17</td>\n      <td>0.01</td>\n      <td>0.13</td>\n      <td>0.07</td>\n      <td>0.00</td>\n      <td>0.07</td>\n      <td>0.15</td>\n      <td>-0.08</td>\n      <td>0.10</td>\n      <td>0.04</td>\n    </tr>\n    <tr>\n      <th>Spargelstücke</th>\n      <td>0.15</td>\n      <td>1.00</td>\n      <td>0.07</td>\n      <td>0.17</td>\n      <td>0.48</td>\n      <td>0.58</td>\n      <td>0.48</td>\n      <td>0.18</td>\n      <td>0.49</td>\n      <td>0.57</td>\n      <td>...</td>\n      <td>0.47</td>\n      <td>0.37</td>\n      <td>0.13</td>\n      <td>0.04</td>\n      <td>0.28</td>\n      <td>0.51</td>\n      <td>0.26</td>\n      <td>0.13</td>\n      <td>0.49</td>\n      <td>0.06</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.40</td>\n      <td>0.07</td>\n      <td>1.00</td>\n      <td>-0.09</td>\n      <td>0.04</td>\n      <td>0.05</td>\n      <td>0.09</td>\n      <td>-0.13</td>\n      <td>0.15</td>\n      <td>0.06</td>\n      <td>...</td>\n      <td>0.08</td>\n      <td>-0.03</td>\n      <td>0.14</td>\n      <td>0.23</td>\n      <td>-0.15</td>\n      <td>0.07</td>\n      <td>0.10</td>\n      <td>-0.17</td>\n      <td>0.07</td>\n      <td>0.10</td>\n    </tr>\n    <tr>\n      <th>bringen</th>\n      <td>0.03</td>\n      <td>0.17</td>\n      <td>-0.09</td>\n      <td>1.00</td>\n      <td>0.48</td>\n      <td>0.03</td>\n      <td>0.03</td>\n      <td>0.43</td>\n      <td>0.20</td>\n      <td>0.13</td>\n      <td>...</td>\n      <td>0.09</td>\n      <td>0.21</td>\n      <td>-0.01</td>\n      <td>-0.02</td>\n      <td>0.34</td>\n      <td>0.02</td>\n      <td>0.11</td>\n      <td>0.24</td>\n      <td>-0.03</td>\n      <td>0.08</td>\n    </tr>\n    <tr>\n      <th>vermengen</th>\n      <td>0.20</td>\n      <td>0.48</td>\n      <td>0.04</td>\n      <td>0.48</td>\n      <td>1.00</td>\n      <td>0.34</td>\n      <td>0.38</td>\n      <td>0.44</td>\n      <td>0.53</td>\n      <td>0.35</td>\n      <td>...</td>\n      <td>0.45</td>\n      <td>0.25</td>\n      <td>0.14</td>\n      <td>0.02</td>\n      <td>0.35</td>\n      <td>0.16</td>\n      <td>0.23</td>\n      <td>0.40</td>\n      <td>0.24</td>\n      <td>0.10</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>Baguette</th>\n      <td>0.07</td>\n      <td>0.51</td>\n      <td>0.07</td>\n      <td>0.02</td>\n      <td>0.16</td>\n      <td>0.54</td>\n      <td>0.42</td>\n      <td>0.07</td>\n      <td>0.35</td>\n      <td>0.54</td>\n      <td>...</td>\n      <td>0.33</td>\n      <td>0.32</td>\n      <td>0.12</td>\n      <td>0.04</td>\n      <td>0.18</td>\n      <td>1.00</td>\n      <td>0.17</td>\n      <td>-0.02</td>\n      <td>0.54</td>\n      <td>0.10</td>\n    </tr>\n    <tr>\n      <th>Schiene</th>\n      <td>0.15</td>\n      <td>0.26</td>\n      <td>0.10</td>\n      <td>0.11</td>\n      <td>0.23</td>\n      <td>0.15</td>\n      <td>0.06</td>\n      <td>0.20</td>\n      <td>0.20</td>\n      <td>0.15</td>\n      <td>...</td>\n      <td>0.16</td>\n      <td>0.12</td>\n      <td>0.23</td>\n      <td>-0.01</td>\n      <td>0.01</td>\n      <td>0.17</td>\n      <td>1.00</td>\n      <td>0.09</td>\n      <td>0.17</td>\n      <td>0.17</td>\n    </tr>\n    <tr>\n      <th>mehreren</th>\n      <td>-0.08</td>\n      <td>0.13</td>\n      <td>-0.17</td>\n      <td>0.24</td>\n      <td>0.40</td>\n      <td>-0.00</td>\n      <td>0.02</td>\n      <td>0.21</td>\n      <td>0.09</td>\n      <td>0.09</td>\n      <td>...</td>\n      <td>0.08</td>\n      <td>0.13</td>\n      <td>0.01</td>\n      <td>0.04</td>\n      <td>0.41</td>\n      <td>-0.02</td>\n      <td>0.09</td>\n      <td>1.00</td>\n      <td>-0.08</td>\n      <td>0.05</td>\n    </tr>\n    <tr>\n      <th>Sauerrahm</th>\n      <td>0.10</td>\n      <td>0.49</td>\n      <td>0.07</td>\n      <td>-0.03</td>\n      <td>0.24</td>\n      <td>0.62</td>\n      <td>0.57</td>\n      <td>0.01</td>\n      <td>0.45</td>\n      <td>0.67</td>\n      <td>...</td>\n      <td>0.49</td>\n      <td>0.19</td>\n      <td>0.26</td>\n      <td>0.01</td>\n      <td>0.08</td>\n      <td>0.54</td>\n      <td>0.17</td>\n      <td>-0.08</td>\n      <td>1.00</td>\n      <td>0.15</td>\n    </tr>\n    <tr>\n      <th>hart</th>\n      <td>0.04</td>\n      <td>0.06</td>\n      <td>0.10</td>\n      <td>0.08</td>\n      <td>0.10</td>\n      <td>0.14</td>\n      <td>0.10</td>\n      <td>0.10</td>\n      <td>0.20</td>\n      <td>0.16</td>\n      <td>...</td>\n      <td>0.14</td>\n      <td>0.22</td>\n      <td>0.53</td>\n      <td>0.02</td>\n      <td>0.18</td>\n      <td>0.10</td>\n      <td>0.17</td>\n      <td>0.05</td>\n      <td>0.15</td>\n      <td>1.00</td>\n    </tr>\n  </tbody>\n</table>\n<p>200 rows × 200 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 143
    }
   ],
   "source": [
    "# Similarity Matrix\n",
    "trim = min(len(tokens), 200)\n",
    "round_to = 2 # Nachkommastellen\n",
    "mat = np.zeros((trim,trim))\n",
    "print(mat)\n",
    "for i,token1 in enumerate(tokens[:trim]):\n",
    "    for k,token2 in enumerate(tokens[:trim]):\n",
    "        mat[i,k] = round(token1.similarity(token2),round_to)\n",
    "print(mat)\n",
    "names = [ token.text for token in tokens[:trim]]\n",
    "sims = pd.DataFrame(mat, columns = names, index = names)\n",
    "# sims.index\n",
    "sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "vermischen    0.83\n",
       "verrühren     0.82\n",
       "pürieren      0.78\n",
       "unterheben    0.76\n",
       "marinieren    0.72\n",
       "Name: vermengen, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 147
    }
   ],
   "source": [
    "# Get the n mst similar words\n",
    "word = \"vermengen\"\n",
    "count = 5\n",
    "sims.nlargest(count+1, word)[word].iloc[1:] # Cut irrelvant columns and the similarity to itself (always 1.00 thus index 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust training data / word vectors with cooking vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}